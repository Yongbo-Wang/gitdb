# 多模态情绪分析论文
|Year|Title|Network|Publish|Paper|Code|Read|
|:-:|:-:|:-:|:-:|:-:|:-:|:-:|
|2019|Multimodal Transformer for Unaligned Multimodal Language Sequences|MulT|ACL|[link](https://arxiv.org/abs/1906.00295)|[link](https://github.com/yaohungt/Multimodal-Transformer)|√|
|2020|CM-BERT: Cross-Modal BERT for Text-Audio Sentiment Analysis|CM-BERT|ACM MM|[link](https://dl.acm.org/doi/10.1145/3394171.3413690)|[link](https://github.com/thuiar/Cross-Modal-BERT)|√|
|2020|Integrating Multimodal Information in Large Pretrained Transformers|MAG|ACL|[link](https://arxiv.org/abs/1908.05787)|[link](https://github.com/WasifurRahman/BERT_multimodal_transformer)|√|
|2020|MISA: Modality-Invariant and -Specific Representations for Multimodal Sentiment Analysis|MISA|ACM MM|[link](https://doi.org/10.1145/3394171.3413678)|[link](https://github.com/declare-lab/MISA)|√|
|2021|Bi-Bimodal Modality Fusion for Correlation-Controlled Multimodal Sentiment Analysis|BBFN|ICMI|[link](https://doi.org/10.1145/1122445.1122456)|[link](https://github.com/declare-lab/multimodal-deep-learning)||
|2021|CTNet: Conversational Transformer Network for Emotion Recognition|CTNet|IEEE-ACM T AUDIO SPE|[link](https://ieeexplore.ieee.org/document/9316758)|-||
|2021|Hybrid Contrastive Learning of Tri-Modal Representation for Multimodal Sentiment Analysis|HyCon|Under Review|[link](https://arxiv.org/abs/2109.01797)|-|√|
|2021|Improving Multimodal Fusion with Hierarchical Mutual Information Maximization for Multimodal Sentiment Analysis|MMIM|EMNLP|[link](https://arxiv.org/pdf/2109.00412.pdf)|[link](https://github.com/declare-lab/Multimodal-Infomax)||
|2021|Learning Modality-Specific Representations with Self-Supervised Multi-Task Learning for Multimodal Sentiment Analysis|Self-MM|AAAI|[link](https://arxiv.org/abs/2102.04830)|[link](https://github.com/thuiar/Self-MM)|√|
|2021|MSAF: Multimodal Split Attention Fusion|MSAF|Under Review|[link](https://arxiv.org/abs/2012.07175)|-|√|
|2022|AMOA: Global Acoustic Feature Enhanced Modal-Order-Aware Network for Multimodal Sentiment Analysis|AMOA|COLING|[link](https://aclanthology.org/2022.coling-1.623/)|-|√|
|2022|BAFN: Bi-direction Attention based Fusion Network for Multimodal Sentiment Analysis|BAFN|TCSVT|[link](https://ieeexplore.ieee.org/document/9932611)|-||
|2022|CLMLF:A Contrastive Learning and Multi-Layer Fusion Method for Multimodal Sentiment Detection|CLMLF|NAACL|[link](https://arxiv.org/abs/2204.05515)|[link](https://github.com/Link-Li/CLMLF)||
|2022|Counterfactual Reasoning for Out-of-distribution Multimodal Sentiment Analysis|CLUE|ACM MM|[link](https://dl.acm.org/doi/10.1145/3503161.3548211)|[link](https://github.com/Teng-Sun/CLUE_model)|√|
|2022|CubeMLP: An MLP-based Model for Multimodal Sentiment Analysis and Depression Estimation|CubeMLP|ACM MM|[link](https://doi.org/10.1145/3503161.3548025)|-|√|
|2022|Disentangled Representation Learning for Multimodal Emotion Recognition|FDMER|ACM MM|[link](https://doi.org/10.1145/3503161.3547754)|-||
|2022|Dynamically Adjust Word Representations Using Unaligned Multimodal Information|CHFN|ACM MM|[link](https://doi.org/10.1145/3503161.3548137)|-||
|2022|EmoCaps: Emotion Capsule based Model for Conversational Emotion Recognition|EmoCaps|ACL|[link](https://arxiv.org/abs/2203.13504)|-|√|
|2022|FEW-SHOT MULTIMODAL SENTIMENT ANALYSIS BASED ON MULTIMODAL PROBABILISTIC FUSION PROMPTS|MultiPoint|Under Review|[link](https://arxiv.org/abs/2211.06607)|[link](https://github.com/YangXiaocui1215/MultiPoint)||
|2022|Leveraging Multi-modal Interactions among the Intermediate Representations of Deep Transformers for Emotion Recognition|RILA|ACM MM|[link](https://doi.org/10.1145/3551876.3554813)|-||
|2022|M-SENA: An Integrated Platform for Multimodal Sentiment Analysis|M-SENA|ACL|[link](https://arxiv.org/abs/2203.12441)|[link](https://github.com/thuiar/M-SENA)|√|
|2022|Multimodal Contrastive Learning via Uni-Modal Coding and Cross-Modal Prediction for Multimodal Sentiment Analysis|MMCL|EMNLP|[link](https://arxiv.org/abs/2210.14556)|-||
|2022|Multimodal Information Bottleneck: Learning Minimal Sufficient Unimodal and Multimodal Representations|MIB|TMM|[link](https://arxiv.org/abs/2210.17444)|[link](https://github.com/TmacMai/Multimodal-Information-Bottleneck)||
|2022|MULTIMODAL SENTIMENT ANALYSIS ON UNALIGNED SEQUENCES VIA HOLOGRAPHIC EMBEDDING|HEMT|ICASSP|[link](https://ieeexplore.ieee.org/document/9747646)|-||
|2022|Multimodal Temporal Attention in Sentiment Analysis|MMTA|ACM MM|[link](https://dl.acm.org/doi/10.1145/3551876.3554811)|-||
|2022|TVLT: Textless Vision-Language Transformer|TVLT|NeurIPS|[link](https://arxiv.org/abs/2209.14156)|[link](https://github.com/zinengtang/TVLT)|√|
|2022|Unified Multi-modal Pre-training for Few-shot Sentiment Analysis with Prompt-based Learning|UP-MPF|ACM MM|[link](https://doi.org/10.1145/3503161.3548306)|[link](https://github.com/yynj98/UP-MPF)|√|
|2022|UniMSE: Towards Unified Multimodal Sentiment Analysis and Emotion Recognition|UniMSE|EMNLP|[link](https://arxiv.org/pdf/2211.11256.pdf)|[link](https://github.com/LeMei/UniMSE)|√|
|2023|A Deep Multi-level Attentive Network for Multimodal Sentiment Analysis|DMLANet|ACM MM|[link](https://doi.org/10.1145/3517139)|-||
|2023|PS-Mixer: A Polar-Vector and Strength-Vector Mixer Model for Multimodal Sentiment Analysis|PS-Mixer|IPM|[link](https://doi.org/10.1016/j.ipm.2022.103229)|[link](https://github.com/metaphysicser/PS-Mixer)||

# 多模态情绪分析模态缺失论文
|Year|Title|Network|Publish|Paper|Code|Read|
|:-:|:-:|:-:|:-:|:-:|:-:|:-:|
|2021|CTFN: Hierarchical Learning for Multimodal Sentiment Analysis Using Coupled-Translation Fusion Network|CTFN|ACL|[link](https://aclanthology.org/2021.acl-long.412/)|[link](https://github.com/deepsuperviser/CTFN)|√|
|2021|Missing Modality Imagination Network for Emotion Recognition with Uncertain Missing Modalities|MMIN|ACL|[link](https://aclanthology.org/2021.acl-long.203/)|[link](https://github.com/AIM3-RUC/MMIN/tree/master)|√|
|2021|Transformer-based Feature Reconstruction Network for Robust Multimodal Sentiment Analysis|TFR-Net|ACM MM|[link](https://www.researchgate.net/publication/355385472_Transformer-based_Feature_Reconstruction_Network_for_Robust_Multimodal_Sentiment_Analysis)|[link](https://github.com/thuiar/TFR-Net)|√|
|2022|Analyzing Modality Robustness in Multimodal Sentiment Analysis|-|NAACL|[link](https://arxiv.org/pdf/2205.15465.pdf)|[link](https://github.com/declare-lab/MSA-Robustness)|√|
|2022|Efficient Multimodal Transformer with Dual-Level Feature Restoration for Robust Multimodal Sentiment Analysis|EMT-DLFR|Under Review|[link](https://arxiv.org/abs/2208.07589)|-||
|2022|EXPLOITING MODALITY-INVARIANT FEATURE FOR ROBUST MULTIMODAL EMOTION RECOGNITION WITH MISSING MODALITIES|IF-MM|ICASSP|[link](https://arxiv.org/abs/2210.15359)|[link](https://github.com/ZhuoYulang/IF-MMIN)|√|
|2022|Mitigating Inconsistencies in Multimodal Sentiment Analysis under Uncertain Missing Modalities|EMMR|EMNLP|[link](https://aclanthology.org/2022.emnlp-main.189/)|[link](https://github.com/JaydenZeng/EMMR)|√|
|2022|MM-Align: Learning Optimal Transport-based Alignment Dynamics for Fast and Accurate Inference on Missing Modality Sequences|MM-Align|EMNLP|[link](https://arxiv.org/pdf/2210.12798.pdf)|[link](https://github.com/declare-lab/MM-Align)|√|
|2022|Robust Multimodal Sentiment Analysis via Tag Encoding of Uncertain Missing Modalities|TATE|TMM|[link](https://ieeexplore.ieee.org/document/9894726)|[link](https://github.com/JaydenZeng/TATE)|√|
|2023|GCNet: Graph Completion Network for Incomplete Multimodal Learning in Conversation|GCNet|TPAMI|[link](https://ieeexplore.ieee.org/abstract/document/10008078)|[link](https://github.com/zeroQiaoba/GCNet)|√|
<!--stackedit_data:
eyJoaXN0b3J5IjpbNzQ1NjIwMjAwXX0=
-->